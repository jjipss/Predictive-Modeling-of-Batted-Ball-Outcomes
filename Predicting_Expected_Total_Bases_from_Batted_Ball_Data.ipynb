{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Predicting Expected Total Bases from Batted Ball Data\n",
        "\n",
        "This notebook uses the TrackMan 2022 dataset to build predictive models of expected total bases\n",
        "for batted balls in baseball. We compare Random Forest and XGBoost models,\n",
        "using features like exit speed, launch angle, spin rate, and more."
      ],
      "metadata": {
        "id": "9XKCkfKupm9x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Upload & Cleaning\n"
      ],
      "metadata": {
        "id": "xbhGIaBKo8eZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "# Load dataset into DataFrame\n",
        "trackman = pd.read_csv(\"Trackman(2).csv\")\n",
        "print(trackman.head(5))\n",
        "\n",
        "# Keep only rows with valid batted ball events\n",
        "trackman = trackman[trackman[\"PlayResult\"].notnull()]\n",
        "\n",
        "# Drop rows with nulls to improve model accuracy\n",
        "trackman = trackman.dropna(subset=[\"ExitSpeed\", \"Angle\", \"Distance\", \"Direction\", \"HitType\", \"HitSpinRate\", \"HangTime\",  \"MaxHeight\", \"VertApprAngle\", \"HorzApprAngle\"])\n",
        "\n"
      ],
      "metadata": {
        "id": "IUuUDFPGZdxD",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Target Variable Construction\n"
      ],
      "metadata": {
        "id": "Ito2GvZkpC2x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Map play results to total bases\n",
        "total_base_map = {\n",
        "    \"Single\": 1,\n",
        "    \"Double\": 2,\n",
        "    \"Triple\": 3,\n",
        "    \"HomeRun\": 4\n",
        "}\n",
        "\n",
        "trackman[\"TotalBases\"] = trackman[\"PlayResult\"].map(total_base_map).fillna(0)"
      ],
      "metadata": {
        "id": "kXbU_mqxeaNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Selection & Encoding\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_82yoEmTpIOe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Select features for modeling\n",
        "features = [\n",
        "    \"ExitSpeed\", \"Angle\", \"Direction\", \"Distance\", \"HitSpinRate\", \"HangTime\",\n",
        "    \"MaxHeight\", \"VertApprAngle\", \"HorzApprAngle\", \"HitType\"\n",
        "]\n",
        "\n",
        "# Keep only selected features and target, drop nulls\n",
        "trackman = trackman[features + [\"TotalBases\"]].dropna()\n",
        "\n",
        "# One-hot encode HitType feature\n",
        "trackman = pd.get_dummies(trackman, columns=[\"HitType\"], drop_first=True)"
      ],
      "metadata": {
        "id": "3w6FEE9Pg7R1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest Model\n"
      ],
      "metadata": {
        "id": "B2nVm3J9pU6P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "\n",
        "\n",
        "# Split data 80/20 into train and test sets\n",
        "X = trackman.drop(\"TotalBases\", axis=1)\n",
        "y = trackman[\"TotalBases\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize Random Forest model\n",
        "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred = rf.predict(X_test)\n",
        "\n",
        "# Evaluate model with RMSE and R²\n",
        "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred)))\n",
        "print(\"R²:\", r2_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "uQkOLf8Jj4GX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter Tuning with GridSearchCV\n"
      ],
      "metadata": {
        "id": "BIqrdLuaDY3T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "import numpy as np\n",
        "\n",
        "# Define parameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_leaf': [1, 2],\n",
        "    'max_features': ['sqrt', 'log2']\n",
        "}\n",
        "\n",
        "# Initialize Random Forest model\n",
        "rf_model = RandomForestRegressor(random_state=42)\n",
        "\n",
        "# Configure GridSearchCV\n",
        "grid = GridSearchCV(\n",
        "    estimator=rf_model,\n",
        "    param_grid=param_grid,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    cv=5,\n",
        "    verbose=1,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Fit grid search on training data\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "# Use best model from grid search\n",
        "best_rf = grid.best_estimator_\n",
        "y_pred = best_rf.predict(X_test)\n",
        "\n",
        "# Evaluate tuned model with RMSE and R²\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"Best Parameters:\", grid.best_params_)\n",
        "print(\"RMSE:\", rmse)\n",
        "print(\"R²:\", r2)"
      ],
      "metadata": {
        "id": "ResKfTKcCRjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Comparison: Random Forest vs. XGBoost\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "-IbUR5JjbP_E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Baseline XGBoost (no tuning)\n",
        "# Train baseline XGBoost model\n",
        "xgb_model = xgb.XGBRegressor(\n",
        "    objective='reg:squarederror',\n",
        "    n_estimators=100,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.1,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate baseline model with RMSE and R²\n",
        "y_pred = xgb_model.predict(X_test)\n",
        "\n",
        "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred)))\n",
        "print(\"R²:\", r2_score(y_test, y_pred))\n",
        "\n"
      ],
      "metadata": {
        "id": "au1sXF7lbVSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter Tuning for XGBoost"
      ],
      "metadata": {
        "id": "i9kv8YMDq6M5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Hyperparameter tuning for XGBoost\n",
        "param_grid = {\n",
        "    'max_depth': [4, 6, 8],\n",
        "    'learning_rate': [0.05, 0.1, 0.2],\n",
        "    'n_estimators': [100, 200],\n",
        "    'subsample': [0.8, 1.0],\n",
        "    'colsample_bytree': [0.8, 1.0]\n",
        "}\n",
        "\n",
        "# Initialize XGBoost model\n",
        "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
        "\n",
        "# Configure GridSearchCV\n",
        "grid = GridSearchCV(\n",
        "    estimator=xgb_model,\n",
        "    param_grid=param_grid,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    cv=5,\n",
        "    verbose=1,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Fit GridSearchCV on training data\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate best tuned model on test set\n",
        "best_xgb = grid.best_estimator_\n",
        "y_pred = best_xgb.predict(X_test)\n",
        "\n",
        "print(\"Best Parameters:\", grid.best_params_)\n",
        "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred)))\n",
        "print(\"R²:\", r2_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "dsW5WtUKe66s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Correlation Analysis"
      ],
      "metadata": {
        "id": "vZOP_gv7rJ0R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Combine features and target for correlation analysis\n",
        "corr_df = X_train.copy()\n",
        "corr_df[\"TotalBases\"] = y_train\n",
        "\n",
        "# Compute correlation matrix\n",
        "corr_matrix = corr_df.corr()\n",
        "\n",
        "# Plot heatmap of correlations\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", square=True)\n",
        "plt.title(\"Correlation Matrix of Features\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "F082_5s_mGts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shap\n",
        "import shap\n"
      ],
      "metadata": {
        "id": "9RAajV0Ng-Lb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Interpreting Model Predictions with SHAP"
      ],
      "metadata": {
        "id": "Kp9yZ1AUriai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create SHAP explainer for tuned XGBoost model\n",
        "explainer = shap.TreeExplainer(best_xgb)\n",
        "\n",
        "# Compute SHAP values for test set\n",
        "shap_values = explainer.shap_values(X_test)\n",
        "\n",
        "\n",
        "# Bar plot for feature importances\n",
        "shap.summary_plot(shap_values, X_test, plot_type=\"bar\")"
      ],
      "metadata": {
        "id": "ub-10imJhgVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Feature Selection and Dimensionality Reduction\n",
        "\n"
      ],
      "metadata": {
        "id": "afhnE0DRmTd0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Drop low-importance features based on SHAP values\n",
        "low_impact_features = ['HitType_PopUp', 'HitType_GroundBall', 'VertApprAngle', 'HorzApprAngle', 'HangTime']\n",
        "X_reduced = X.drop(columns=low_impact_features)\n",
        "\n",
        "# Split reduced dataset 80/20 into train/test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_reduced, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define parameter grid\n",
        "param_grid = {\n",
        "    'max_depth': [4, 6, 8],\n",
        "    'learning_rate': [0.05, 0.1, 0.2],\n",
        "    'n_estimators': [100, 200],\n",
        "    'subsample': [0.8, 1.0],\n",
        "    'colsample_bytree': [0.8, 1.0]\n",
        "}\n",
        "\n",
        "# Initialize XGBoost model\n",
        "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
        "\n",
        "# Configure GridSearchCV\n",
        "grid = GridSearchCV(\n",
        "    estimator=xgb_model,\n",
        "    param_grid=param_grid,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    cv=5,\n",
        "    verbose=1,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Fit model on reduced feature set\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "# Predict with best estimator\n",
        "best_xgb = grid.best_estimator_\n",
        "y_pred = best_xgb.predict(X_test)\n",
        "\n",
        "# Evaluate with RMSE and R²\n",
        "print(\"Best Parameters:\", grid.best_params_)\n",
        "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred)))\n",
        "print(\"R²:\", r2_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "DQj2ZtEFjkeT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusions\n",
        "- Random Forest and XGBoost performed well, with XGBoost slightly stronger after tuning.\n",
        "- ExitSpeed and Launch Angle were the most important predictors.\n",
        "- Removing low-importance features simplified the model without hurting performance."
      ],
      "metadata": {
        "id": "BxZbbgL2xAL9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open(\"model.pkl\", \"wb\") as f:\n",
        "    pickle.dump(best_xgb, f)"
      ],
      "metadata": {
        "id": "VUXiNt79xSlw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"model.pkl\")"
      ],
      "metadata": {
        "id": "_xAMngTzzgaf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}